{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96f54b67-61a0-4182-9851-33d0d6e65af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 0\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "#from fastai import *\n",
    "#from fastai.text.all import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, roc_curve, recall_score, f1_score, classification_report\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf37084",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/home/sm1073/.cache/huggingface/hub/models--zhihan1996--DNABERT-2-117M/DNABERT-2-117M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ab9e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sm1073/.cache/huggingface/modules/transformers_modules/DNABERT-2-117M/bert_layers.py:127: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/sm1073/.cache/huggingface/hub/models--zhihan1996--DNABERT-2-117M/DNABERT-2-117M and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d41bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/sm1073/Documents/independent_project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a98f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneName</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASMTL</td>\n",
       "      <td>AAGTGCGGACGCCCGGCTCCCGGCGTGGACGCCATGGTGCTGTGCC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIBC1</td>\n",
       "      <td>CGGGCGACCGGCAAATGTCGCGAGAATACGTCCAGGCCTAACGGGA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MPC1L</td>\n",
       "      <td>CTGTGGCGGAAGATGAGAGATAACTTCCAGAGCAAGGAGTTCCGGG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDX3X</td>\n",
       "      <td>CTTTCCCCTTACTCCGCTCCCCTCTTTTCCCTCCCTCTCCTCCCCT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDHD1</td>\n",
       "      <td>CTCAGTGCGCGTGCGCGGGGCGGGCGGGTGCGCGCGCACTTCCTCC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GeneName                                           Sequence  Label\n",
       "0    ASMTL  AAGTGCGGACGCCCGGCTCCCGGCGTGGACGCCATGGTGCTGTGCC...      1\n",
       "1    RIBC1  CGGGCGACCGGCAAATGTCGCGAGAATACGTCCAGGCCTAACGGGA...      1\n",
       "2    MPC1L  CTGTGGCGGAAGATGAGAGATAACTTCCAGAGCAAGGAGTTCCGGG...      1\n",
       "3    DDX3X  CTTTCCCCTTACTCCGCTCCCCTCTTTTCCCTCCCTCTCCTCCCCT...      1\n",
       "4    HDHD1  CTCAGTGCGCGTGCGCGGGGCGGGCGGGTGCGCGCGCACTTCCTCC...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'x_inactivation_genes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fa1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3dc969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.Sequence\n",
    "        self.labels = dataframe.Label\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dna_sequence = str(self.text.iloc[index])\n",
    "        inputs = self.tokenizer(dna_sequence, return_tensors='pt', max_length=self.max_len, padding='max_length', truncation=True)\n",
    "        labels = self.labels.iloc[index]\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efbf9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa24e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DNADataset(train_df, tokenizer, max_len=512)\n",
    "val_dataset = DNADataset(val_df, tokenizer, max_len=512)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee3f2244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 20:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.673200</td>\n",
       "      <td>0.699614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6989232897758484, 'eval_runtime': 34.8368, 'eval_samples_per_second': 1.148, 'eval_steps_per_second': 0.144, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d61663-78d6-4fa5-9453-6fc9acfb8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNADatasetForPrediction(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.Sequence\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dna_sequence = str(self.text.iloc[index])\n",
    "        inputs = self.tokenizer(dna_sequence, return_tensors='pt', max_length=self.max_len, padding='max_length', truncation=True)\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd3aa1de-ae0c-4b20-a41f-af6f48fba967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(4096, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertUnpadAttention(\n",
       "            (self): BertUnpadSelfAttention(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (mlp): BertGatedLinearUnitMLP(\n",
       "            (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
       "            (act): GELU(approximate='none')\n",
       "            (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset\n",
    "predict_dataset = DNADatasetForPrediction(df, tokenizer, max_len=512)\n",
    "#dataloader\n",
    "predict_dataloader = DataLoader(predict_dataset, sampler=SequentialSampler(predict_dataset), batch_size=8)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c9b1d48-070b-4c00-876c-d30255691542",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in predict_dataloader:\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'],\n",
    "            'attention_mask': batch['attention_mask']\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.softmax(logits, dim=1).cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b372fde8-ec1a-4f7a-add3-7d78409870a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.486771   0.513229  ]\n",
      " [0.5210752  0.47892484]\n",
      " [0.49427083 0.50572914]\n",
      " [0.4994406  0.5005594 ]\n",
      " [0.50485295 0.49514702]\n",
      " [0.50629497 0.4937051 ]\n",
      " [0.49804747 0.50195247]\n",
      " [0.49493086 0.50506914]\n",
      " [0.5103201  0.48967984]\n",
      " [0.5359552  0.46404478]\n",
      " [0.5162862  0.48371384]\n",
      " [0.5280626  0.47193748]\n",
      " [0.48489118 0.51510876]\n",
      " [0.51309896 0.48690102]\n",
      " [0.50312674 0.4968733 ]\n",
      " [0.5176405  0.4823595 ]\n",
      " [0.54898036 0.45101956]\n",
      " [0.5208816  0.47911844]\n",
      " [0.54039896 0.45960099]\n",
      " [0.5050372  0.4949628 ]\n",
      " [0.5163076  0.48369244]\n",
      " [0.48166674 0.51833326]\n",
      " [0.49509546 0.50490457]\n",
      " [0.5396035  0.46039647]\n",
      " [0.5252875  0.4747125 ]\n",
      " [0.4948651  0.5051349 ]\n",
      " [0.46449602 0.535504  ]\n",
      " [0.5044936  0.49550644]\n",
      " [0.50871044 0.49128956]\n",
      " [0.51682687 0.48317304]\n",
      " [0.513368   0.48663193]\n",
      " [0.50653946 0.4934605 ]\n",
      " [0.51430655 0.48569348]\n",
      " [0.5223847  0.4776153 ]\n",
      " [0.5034893  0.49651074]\n",
      " [0.4955704  0.50442964]\n",
      " [0.5208514  0.4791486 ]\n",
      " [0.5202584  0.47974154]\n",
      " [0.50790006 0.4921    ]\n",
      " [0.5547467  0.44525322]\n",
      " [0.5281244  0.4718756 ]\n",
      " [0.49865583 0.5013441 ]\n",
      " [0.5328853  0.46711463]\n",
      " [0.5153711  0.48462886]\n",
      " [0.5274722  0.47252774]\n",
      " [0.5030367  0.4969634 ]\n",
      " [0.4822533  0.5177467 ]\n",
      " [0.4954049  0.50459516]\n",
      " [0.48513952 0.51486045]\n",
      " [0.49595907 0.504041  ]\n",
      " [0.5160679  0.4839321 ]\n",
      " [0.52221155 0.4777885 ]\n",
      " [0.48746604 0.5125339 ]\n",
      " [0.5106111  0.48938894]\n",
      " [0.51036435 0.48963565]\n",
      " [0.49922553 0.5007745 ]\n",
      " [0.5463768  0.45362318]\n",
      " [0.50194997 0.4980501 ]\n",
      " [0.505756   0.49424404]\n",
      " [0.4946022  0.50539774]\n",
      " [0.5386518  0.46134818]\n",
      " [0.48551396 0.5144861 ]\n",
      " [0.50247794 0.4975221 ]\n",
      " [0.49107397 0.5089261 ]\n",
      " [0.48761743 0.5123825 ]\n",
      " [0.49758318 0.50241685]\n",
      " [0.51302725 0.48697272]\n",
      " [0.5358502  0.46414974]\n",
      " [0.50974375 0.49025628]\n",
      " [0.54324543 0.45675457]\n",
      " [0.49939886 0.5006012 ]\n",
      " [0.54552406 0.45447594]\n",
      " [0.5243466  0.4756534 ]\n",
      " [0.4798848  0.5201152 ]\n",
      " [0.53147626 0.46852365]\n",
      " [0.52077097 0.479229  ]\n",
      " [0.5200194  0.47998056]\n",
      " [0.5232994  0.4767005 ]\n",
      " [0.5495105  0.45048955]\n",
      " [0.47390267 0.52609736]\n",
      " [0.5164358  0.48356426]\n",
      " [0.4945507  0.5054493 ]\n",
      " [0.5260615  0.4739385 ]\n",
      " [0.5081781  0.49182191]\n",
      " [0.52056324 0.47943673]\n",
      " [0.52652603 0.47347397]\n",
      " [0.5122717  0.48772827]\n",
      " [0.51558083 0.48441917]\n",
      " [0.49344411 0.50655586]\n",
      " [0.52571404 0.47428596]\n",
      " [0.49154514 0.50845486]\n",
      " [0.5369107  0.46308935]\n",
      " [0.50338876 0.4966112 ]\n",
      " [0.49360695 0.506393  ]\n",
      " [0.50217086 0.49782905]\n",
      " [0.51871175 0.48128828]\n",
      " [0.5140406  0.48595935]\n",
      " [0.51605153 0.4839484 ]\n",
      " [0.5193035  0.4806964 ]\n",
      " [0.50816035 0.49183974]\n",
      " [0.5287509  0.4712491 ]\n",
      " [0.5356548  0.46434516]\n",
      " [0.534252   0.46574804]\n",
      " [0.5624596  0.4375404 ]\n",
      " [0.50956696 0.49043298]\n",
      " [0.531557   0.46844295]\n",
      " [0.5127796  0.48722032]\n",
      " [0.52035636 0.4796436 ]\n",
      " [0.49134454 0.5086554 ]\n",
      " [0.5305601  0.4694399 ]\n",
      " [0.52448845 0.47551155]\n",
      " [0.5113019  0.48869812]\n",
      " [0.5418969  0.45810315]\n",
      " [0.5636004  0.43639964]\n",
      " [0.5607805  0.43921953]\n",
      " [0.5503426  0.44965738]\n",
      " [0.5397619  0.4602381 ]\n",
      " [0.50259614 0.4974039 ]\n",
      " [0.5296207  0.47037932]\n",
      " [0.5161263  0.4838737 ]\n",
      " [0.52409905 0.47590095]\n",
      " [0.542858   0.45714194]\n",
      " [0.53312    0.46688002]\n",
      " [0.56295353 0.4370465 ]\n",
      " [0.5198014  0.4801986 ]\n",
      " [0.534989   0.46501097]\n",
      " [0.51554924 0.48445076]\n",
      " [0.5503124  0.4496876 ]\n",
      " [0.5232094  0.47679058]\n",
      " [0.55161124 0.4483887 ]\n",
      " [0.5195562  0.48044375]\n",
      " [0.55378103 0.44621897]\n",
      " [0.5653488  0.43465126]\n",
      " [0.53892523 0.46107474]\n",
      " [0.5523763  0.4476237 ]\n",
      " [0.50932926 0.49067074]\n",
      " [0.53562075 0.46437925]\n",
      " [0.519896   0.48010397]\n",
      " [0.51160127 0.4883987 ]\n",
      " [0.5113796  0.48862037]\n",
      " [0.5122257  0.48777434]\n",
      " [0.5136066  0.4863934 ]\n",
      " [0.5390431  0.46095687]\n",
      " [0.5528351  0.4471649 ]\n",
      " [0.53423613 0.46576384]\n",
      " [0.5471291  0.4528709 ]\n",
      " [0.55294657 0.44705343]\n",
      " [0.54096353 0.45903653]\n",
      " [0.53230613 0.46769387]\n",
      " [0.50968003 0.49031997]\n",
      " [0.54710096 0.45289904]\n",
      " [0.55449677 0.4455032 ]\n",
      " [0.52970403 0.47029603]\n",
      " [0.5365649  0.46343517]\n",
      " [0.514646   0.485354  ]\n",
      " [0.529301   0.470699  ]\n",
      " [0.51101744 0.48898256]\n",
      " [0.5496756  0.45032448]\n",
      " [0.49866894 0.50133103]\n",
      " [0.5550251  0.4449749 ]\n",
      " [0.51365733 0.48634264]\n",
      " [0.5458986  0.45410132]\n",
      " [0.54546463 0.45453537]\n",
      " [0.5516643  0.4483357 ]\n",
      " [0.5071952  0.49280483]\n",
      " [0.4988085  0.50119156]\n",
      " [0.53893846 0.4610616 ]\n",
      " [0.52862895 0.47137097]\n",
      " [0.54232574 0.45767426]\n",
      " [0.53916925 0.46083078]\n",
      " [0.505863   0.49413696]\n",
      " [0.51762426 0.48237577]\n",
      " [0.53004086 0.4699591 ]\n",
      " [0.5250915  0.47490853]\n",
      " [0.5367967  0.4632033 ]\n",
      " [0.49932894 0.500671  ]\n",
      " [0.5227614  0.47723857]\n",
      " [0.49364173 0.5063582 ]\n",
      " [0.5151971  0.48480284]\n",
      " [0.55489635 0.44510362]\n",
      " [0.54357994 0.4564201 ]\n",
      " [0.5126077  0.4873923 ]\n",
      " [0.50357807 0.49642196]\n",
      " [0.5463194  0.45368055]\n",
      " [0.57303226 0.42696777]\n",
      " [0.50547636 0.49452358]\n",
      " [0.5242056  0.47579437]\n",
      " [0.56902486 0.43097517]\n",
      " [0.5323531  0.46764687]\n",
      " [0.53847736 0.46152267]\n",
      " [0.54513496 0.454865  ]\n",
      " [0.5089395  0.4910605 ]\n",
      " [0.5426292  0.4573708 ]\n",
      " [0.5427841  0.45721588]\n",
      " [0.54714274 0.4528572 ]\n",
      " [0.5452028  0.4547972 ]\n",
      " [0.5541787  0.44582126]\n",
      " [0.5533578  0.44664222]\n",
      " [0.5428517  0.45714825]\n",
      " [0.52863514 0.4713649 ]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e5b2428-38b3-48fa-9823-af7b84706ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8cc07d6-20a6-4935-a69b-399130b61a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "precision = precision_score(true_labels, pred_labels, average='weighted')\n",
    "recall = recall_score(true_labels, pred_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
    "#extract probabilities for escape\n",
    "escape_prob = predictions[:,1]\n",
    "roc_auc = roc_auc_score(true_labels, escape_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddd75767-5050-4777-8fca-fff9e7d4cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       101\n",
      "           1       0.86      0.30      0.45        99\n",
      "\n",
      "    accuracy                           0.63       200\n",
      "   macro avg       0.72      0.63      0.58       200\n",
      "weighted avg       0.72      0.63      0.59       200\n",
      "\n",
      "Accuracy: 0.63\n",
      "Precision: 0.718103896103896\n",
      "Recall: 0.63\n",
      "F1 Score: 0.5861530692402649\n",
      "ROC AUC score:0.7772777277727773\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC score:{roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa9d226e-12e5-479c-b2fd-fc8212c56af7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_binarize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m true_labels_binarized \u001b[38;5;241m=\u001b[39m label_binarize(true_labels, classes\u001b[38;5;241m=\u001b[39m[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_classes)])\n\u001b[1;32m      4\u001b[0m fpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m      5\u001b[0m tpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_binarize' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
